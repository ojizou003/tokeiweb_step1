# 統計WEB Step1. 基礎編

2023-11-21 ~ 

## 1. 統計ことはじめ

1-1. ギリシャ文字の読み方

^ ...ハットまたはカレット･･･推定量を意味する

1-2. おすすめの書籍と電卓

■おすすめの4冊！  
- 「統計学入門(基礎統計学)」 東京大学出版
- 「はじめての統計学」 鳥居泰彦 日経BPマーケティング
- 「入門統計学(第2版): 検定から多変量解析・実験計画法・ベイズ統計学まで」 栗原伸一 オーム社
- 「コア・テキスト統計学(ライブラリ経済学コア・テキスト＆最先端)」 大屋幸輔 新世社

■問題を解いて腕試し！
- 「基本統計学[第5版]」 宮川公男 有斐閣
- 「日本統計学公式認定 統計検定 2級 公式問題集[2018~2021年]」 日本統計学会 実務教育出版

■統計検定®2級で使える電卓
  四則演算や百分率、平方根の計算ができる一般電卓または事務用電卓を使うことはできるが、関数電卓は使用不可

1-3. 統計学に必要な数学

- 「！」「P」「C」を使って、階乗・順列・組み合わせの計算ができる
  「P」 ...permuration (math.perm(,))

1-4. 変数の尺度

4つの尺度  
1946年、スタンレー・スティーブンズがサイエンス誌で発表

■名義尺度
- 他と区別し分類するための名称のようなもの
- 例: 男女、血液型、郵便番号、住所、本籍地、所属学部、学籍番号

■順序尺度
- 順序や大小には意味があるが間隔には意味がないもの
- 例: 1位/2位/3位、1.好き/2.ふつう/3.嫌い

■間隔尺度
- 目盛が等間隔になっているもので、その間隔に意味があるもの
- 例: 気温、西暦、テストの点数

■比例尺度
- 0が原点であり、間隔と比率に意味があるもの
- 例: 身長、速度、睡眠時間、値段、給料、幅跳びの記録

名義＜順序＜間隔＜比例という上下関係があり、上位の尺度は下位の尺度が使える統計量を使うことができる  
間隔尺度と比例尺度は見分けづらい場合がある  
見分けるコツは、比をとることができるかどうか  

4つの尺度以外の分け方

- 質的変数と量的変数
  質的変数 ...名義尺度と順序尺度、カテゴリー変数またはカテゴリカル変数ともいう  
  量的変数 ...間隔尺度と比例尺度

- 離散変数と連続変数

1-5. 説明変数と目的変数

説明変数は、「何かの原因となっている変数」のことで、  
目的変数は、「その原因を受けて発生した結果となっている変数」のこと  

■説明変数 x
- 説明変数
- 予測変数
- 独立変数

■目的変数 y
- 目的変数、応答変数、反応変数
- 結果変数
- 従属変数
- 基準変数
- 被説明変数

1-6.学習スケジュール

練習問題(1. 統計ことはじめ)

## 2. 度数分布とヒストグラム

2-1. 度数分布と累積度数分布

データの大まか分布を知るために、データをある幅ごとに区切ってその中に含まれるデータの個数を見るという方法がある  
この表のことを「度数分布表」という  

- 階級：  度数を集計するための区間
- 階級値：    その階級を代表する値で、階級の真ん中の値となる
- 度数：  描く階級に含まれるデータ数
- 相対度数：  各階級の度数が全体に占める割合
- 累積相対度数：    その階級までの相対度数のすべての和

2-2. ヒストグラム

ヒストグラムは、度数分布表をグラフにしたもの
パレード図は、ヒストグラムに累積相対度数の折れ線グラフを重ねたもの

データの分布の山が左側に偏り、右に行くにつれて山がなだらかになっているヒストグラムのことを「右裾が長い」もしくは「右に歪んだ」もしくは「左に偏った」分布という

■棒グラフとヒストグラムの使い分け
- 棒グラフ： 質的データの可視化に使う
- ヒストグラム： 量的データの可視化に使う

2-3. 階級幅の決め方

グラフを一目見て分布の特徴が捉えられるように適切な幅にする
階級幅の決め方で困ったときは「スタージェスの公式」を使うこともできる

■スタージェスの公式
$nをサンプルサイズ、kを階級数とすると、次のように計算することができる$
$k = \log_2N + 1$

2-4. ローレンツ曲線

ローレンツ曲線： 「偏り = 不均等さ」を表す曲線

ローレンツ曲線を作るためには2つの累積相対度数が必要

1. 各階級の度数の累積相対度数
2. 各階級に属する値の累積相対度数

1.を横軸に、2.を縦軸にとった折れ線グラフがローレンツ曲線

完全平等線： ローレンツ曲線における対角線の直線
          分布が完全に均等な場合、ローレンツ曲線は完全平等線に一致する

2-5. ジニ係数

ジニ係数： 「偏り」や「不均等さ」を数値で表したもの

ローレンツ曲線と完全平等線で囲まれた面積の2倍の値
0から1までの値をとり、1に近いほど偏りが大きく、0に近いほど偏りが小さい

2-6. ジニ係数の求め方
     ジニ係数 = (三角形 - (三角形 + 台形 + 台形 + ...)) * 2

練習問題(2. 度数分布とヒストグラム)

## 3. さまざまな代表値

3-1. 平均・中央値・モード

数値からなるデータがある場合に、そのデータを端的に表す値のことを「代表値という」

主な代表値
1. 平均
2. 中央値
3. モード(最頻値)

average と mean
いろいろな mean

統計学ではaverageとmeanを使い分けており、いわゆる平均値にはmeanを用いるのが常識  
くわしくは[こちら](https://bellcurve.jp/statistics/blog/13969.html)

3-2. 平均・中央値・モードの関係

左右対称な分布の場合、「平均」「中央値」「モード」はすべて同じ値
左に偏っている分布の場合、左から「モード」「中央値」「平均」と並ぶことが多い

3-3. 平均・中央値・モードの使い方

ヒストグラムの山が2つ以上ある場合
多峰性(multimodal)といい、特に2つのものを二峰性(bimodal)という
一方、分布の山が1つのものを単峰性(unimodal)という

二峰性のデータの場合、異なる性質の集団が混ざっている可能性がある

3-4. いろいろな平均

■算術平均
  一般的な平均、データの値をすべて足して、データの数で割ったもの

■幾何平均($\overline{x}_G$)
  $\overline{x}_G = \sqrt[n]{x_1\times x_2\times ･･･\times x_n}$

■調和平均($\overline{x}_H$)
  $\overline{x}_H = \frac{n}{\frac{1}{x_1} + \frac{1}{x_2} + ･･･ + \frac{1}{x_n}}$  

■刈込み平均(トリム平均)($\overline{x}_k$)
  $\overline{x}_k = \frac{1}{n-2k}\sum_{i=i+k}^{n-k}x_i$

3-5. 歪度と尖度

■歪度
  分布が正規分布からどれだけ歪んでいるかを表す統計量
  $歪度 = \frac{n}{(n-1)(n-2)}\sum_{i=1}^n(\frac{x_i-\overline{x}}{s})^3$  
左に偏った分布のときには「正」の値を、右に偏った分布のときには「負」の値を、正規分布の場合には「0」になる

■尖度
  分布が正規分布からどれだけ尖っているかを表す統計量で、山の尖り度と裾の広がり度を示す  
  $尖度 = \frac{n(n+1)}{(n-1)(n-2)(n-3)}\sum_{i=1}^n\frac{(x_i-\overline{x})^4}{s^4}-\frac{3(n-1)^2}{(n-2)(n-3)}$
  正規分布より尖った分布のときには「正」の値を、正規分布より扁平な分布のときには「負の」値を、正規分布の場合は「0」になる

練習問題(3. さまざまな代表値)

## 4. 箱ひげ図と幹葉表示

4-1. 箱ひげ図とは

箱ひげ図(Boxplot)は、データの分布を「箱」と「ひげ」で表したグラフで、データがどのあたりの値に集中しているかをひと目で捉えることができる

4-2. 箱ひげ図の見方

■パーセンタイル
  パーセンタイルは、データを小さい順で並べたとき、ある数値が小さい方から見て何％の位置にあるかを表すもの

■四分位数
  第三四分位数 - 第一四分位数 = 四分位範囲(Inter Quarter Range)

箱ひげ図のそれぞれの区間には、同じ個数のデータが入っている

4-3. 外れ値検出のある箱ひげ図

ひげの長さを四分位範囲の1.5倍を上下限とする

外れ値は「✕」または「〇」で表示する

4-4. 箱ひげ図の書き方(データ数が奇数の場合)

4-5. 箱ひげ図の書き方(データ数が偶数の場合)

4-6. 幹葉表示

幹葉表示(stem-and-leaf display)は、データの値そのものを用いて作成するヒストグラムに似た図

練習問題(4. 箱ひげ図と幹葉表示)

箱ひげ図のみから峰の数を読み取ることはできない

## 5. データの集計と表現

5-1. データの集計について

データがどのようなものなのか数字の羅列を見ただけではよく分からない  
データを「可視化する」、つまりひと目見てデータの分布や特徴をつかめるようにすることが重要

■質的データの場合
  可視化にあたりまずデータを「集計」する  
  すべての項目をピックアップし、それぞれの項目の個数をカウントするなど

■量的データの場合  
  基本統計量(平均値、最小値・最大値など)を求める
  ヒストグラムや箱ひげ図などで可視化

5-2. 棒グラフ・円グラフ・折れ線グラフ

■棒グラフ
  棒グラフは、データの大きさを棒の高さで表したグラフ

■円グラフ
  円グラフは、データの大きさを全体の円に対する割合で表したもの
  円グラフを描くコツ
  - 円グラフの項目や割合を書く
  - ドーナツグラフにして合計値を中央に書く
  - 項目が多すぎる場合はまとめる
  - 項目の多い順番に並べる

■折れ線グラフ
  折れ線グラフは、グラフにプロットされたデータの点を時間の経過に従って直線で結んだもの

5-3. クロス集計表1

クロス集計表は、2つのカテゴリーに属するデータをそれぞれのカテゴリーで同時に分類し、その度数を集計したもの

クロス集計表では、左側と上側の項目をそれぞれ「表側」「表頭」という

5-4. クロス集計表2

クロス集計表から各セルの割合を求めると、各項目の割合を比較しやすくなる
- 行パーセント
- 列パーセント
- 総パーセント

■クロス集計表の活用
  クロス集計表を使うと、様々な検定を行うことができる

5-5. 帯グラフ・モザイク図

■帯グラフ
  帯グラフは、クロス集計表において群ごとの割合を比較するためのもの
  積み上げ棒グラフを横向きにした形状で、横の幅がすべて100％で固定されている

■モザイク図
  モザイク図は、クロス集計表の表側のカテゴリーごとに積み上げ100％の縦棒グラフを作成し、さらにこの棒の横幅を表側の各カテゴリーの度数の合計に比例するようにしたグラフ

5-6. 三角グラフ

三角グラフは、3つの要素で構成されるデータにおいて、そお構成比を表す際に用いられるグラフ

練習問題(5. データの集計と表現)

## 6. 分散と標準偏差

6-1. 分散

$分散V = \frac{1}{n}\sum_{n=i}^n(x_i - \overline{x})^2$

6-2. 標準偏差

$標準偏差\sigma = \sqrt{分散}$

6-3. 標準偏差の使い方

標準偏差どうしを比較するためには、単位をそろえる必要がある

6-4. 変動係数

変動係数は、標準偏差を平均値で割った値のこと
単位の異なるデータのばらつきを相対的に評価する際に用いる
単位はもたない

$CV = \frac{\sigma}{\overline{x}}$

【変動係数を使うコツ】
変動係数は、平均値に対して標準偏差が比例関係にあるものに対して適用する
すなわち、比例尺度の場合に有効な指標であり、間隔尺度では参考にならない

練習問題(6. 分散と標準偏差)

## 場合の数

7-1. ！の使い方

$n! = \Pi_{k=1}^nk = n \times (n-1) \times (n-2)\times ･･･ \times 2 \times 1$
$0! = 1$

順列
$_nP_k = \frac{n!}{(n-k)!}$

7-2. Pの使い方

7-3. Cの使い方

練習問題(7. 場合の数)

数珠順列 = 円順列 ÷ 2

## 8. さまざまな事象

8-1. 事象とは

全事象は$\Omega$や$U$で表される
分解が可能な事象を複合事象という
これ以上分解することができない事象を根元事象という

8-2. ベン図

8-3. 余事象・空事象・排反事象

■余事象
  余事象とは、ある場合以外の事象のこと
  $事象Aの余事象はA^cまたは\overline{A}と表記する$
  $A + A^c = \Omega$

■空事象(くうじしょう)
  存在しない事象
  たとえばさいころで7の目がでる事象や偶数でも奇数でもない目が出る事象
  $空事象は、\phiで表す$

■排反事象
  排反事象とは、同時に起こらない事象のこと
  言い換えると、事象Aと事象Bを同時に満たす事象が空事象の場合、事象Aと事象Bは互いに排反事象といえる

8-4. 和事象

事象Aまたは事象Bが起こる事象を和事象という
$A\cup B$

8-5. 積事象

事象Aと事象Bが同時に起こる事象を積事象という
$A\cap B$

練習問題(8. さまざまな事象)

## 9. 確率と期待値

9-1. 確率

事象Aが起こる確率
$P(A)$

【確率の3つの公理】
1. どのような事象についての確率も、0以上1以下となる
2. 全事象を$\Omega$と表すと、全事象の起こる確率$P(\Omega)$は、1となる
3. 互いに排反な事象の和集合の確率は、それぞれの事象の確率の和となる

9-2. 確率の計算(数え上げ)

9-3. 確率の計算(順列・組み合わせ)

9-4. 確率の計算(余事象)

$P(\overline{A}) = 1 -P(A)$

9-5. 確率と独立

お互いの結果が影響しあうことがないとき、2つの事象は「独立である」という
2つの事象が独立である場合、2つの積事象の確率は事象同士の確率の積で算出できる
$P(A\cap B) = P(A) \times P(B)$

9-6. 加法定理

事象Aと事象Bが互いに排反である場合、次の式が成り立つ
$P(A\cup B) = P(A) + P(B)$ 

事象Aと事象Bが互いに排反でない場合、次の式が成り立つ
$P(A\cup B) = P(A) + P(B) - P(A\cap B)$

9-7. 期待値

期待値とは、1回の試行で得られる値の平均値
得られうるすべての値と起こる確率の積を足し合わせたもの
$期待値 = \Sigma_{k=1}^np_kx_k$

練習問題(9. 確率と期待値)

## 10. 条件付き確率とベイズの定理

10-1. 条件付き確率とは

ある事象が起こるという条件のもとで、別のある事象が起こる確率のことを「条件付き確率」という
事象Bが起こるという条件のもとで事象Aが起こる場合、
$P(A|B) = \frac{P(A\cap B)}{P(B)}$

10-2. 条件付き確率と独立

独立の場合
$P(A|B) = P(A)$

排反の場合
$P(A|B) = 0$

10-3. 乗法定理

$P(A\cap B) = P(A)\times P(B|A)$

10-4. ベイズの定理

$P(B_i|A) = \frac{P(A\cap B_i)}{P(A)} = \frac{P(B_i)P(A|B_i)}{P(A)}$

10-5. 事前確率と事後確率

10-6. ベイズの定理の使い方

練習問題(10. 条件付き確率とベイズの定理)

## 11. 確率変数と確率分布

11-1. 確率変数と確率分布

■確率変数
確率変数は、ある変数の値をとる確率が存在する変数のこと

■確率分布
確率変数がとる値とその値をとる確率の対応の様子を確率分布という

11-2. 離散型確率分布と確率質量関数

確率変数には、「離散型」と「連続型」の2種類がある

■離散型確率変数
離散型変数はとびとびの値をとる変数のこと
隣り合う数字の間には値が存在しない
サイコロの出る目や人数なども含まれる
離散型変数それぞれに対応する確率が存在する場合、この変数を離散型確率変数という

■離散型確率分布
隔離変数が離散型である場合の確率分布を「離散型確率分布」あるいは「離散型分布」という

■確率質量関数
離散型確率変数$x$がある値$_x$をとる確率を関数$f(x)$とした場合、$f(x)$は「確率質量関数」とよばれる

11-3. 連続型確率分布

連続型変数は、重さや湿度などのように連続した値をとるものを指す
連続型変数の取りうる値に対応する確率が存在する場合、この変数を「連続型確率変数」という
確率変数が連続型である場合の確率分布を「連続型確率分布」あるいは「連続型分布」という

連続型分布では、確率変数の値をある1点に定めた場合にその値を通る確率は「0」である
$P(x) = \frac{1}{\infty} = 0$

11-4. 確率密度と確率密度関数

■確率密度
確率密度は、定義域内での$x$の値の「相対的なでやすさ」を表すもの

■確率密度関数
連続型確率変数Xがある値xをとる確率密度を関数f(x)とすると、f(x)を確率密度関数と呼ぶ
確率と異なり、$f(x)\geq1$になる場合もある

11-5. 連続型確率分布と確率1

確率密度関数$f(x)$において$a\leq x \leq b$となる確率は次の積分の計算によって求められる
$P(a\leq X \leq b) = \int_a^bf(x)dx$

$\int_{-\infty}^\infty f(x)dx = 1$  

11-6. 連続型確率分布と確率2

【様々な確率分布】

■離散型分布
- 一様分布
- 二項分布
- 多項分布
- ポアソン分布
- 幾何分布

■連続型分布
- 連続一様分布
- 正規分布
- 指数分布
- t分布
- F分布
- カイ二乗分布

## 累積分布関数と確率変数の期待値・分散

12-1.累積分布関数とは

累積分布関数とは、確率変数Xがある値x以下の値となる確率を表す関数
累積分布関数は、大文字の「Ｆ」を用いて「Ｆ(x)」と表される
$F(x) = P(X\leq x)$  

■確率変数が離散型である場合
累積分布関数は、確率変数Ｘのとる値がxとなるまでの確率ｐをすべて足し合わせたものになる

■確率変数が連続型である場合
累積分布関数は、確率密度関数におけるｰ∞からxまでの面積と考えることができる

確率変数が連続型である場合、累積分布関数F(x)は確率密度関数f(x)を積分することで求められる
逆に確率密度関数f(x)は累積分布関数F(x)を微分することで求めることができる

12-2. 累積分布関数の性質

1. $Ｆ(\infty)=1$
2. $F(-\infty)=0$
3. $X\leq Yである場合Ｆ(X)\leq F(Y)$

12-3. 確率変数の期待値

確率変数の期待値は、確率変数の平均値を表す
確率変数$Ｘ$の期待値は$E(X)$と表す

■離散型確率変数の場合
期待値は、確率変数Ｘがとり得るそれぞれの値xに対応する確率ｐを掛け、掛けた結果を全て足し合わせることで算出できる

■連続型確率変数の場合
期待値は、積分によって計算することができる
$E(X) = \int_{-\infty}^\infty xf(x)dx$  

12-4. 期待値の性質

1. $E(C)=C$
2. $E(X+C)=E(X)+E(C)=E(X)+C$
3. $E(kX)=kE(X)$
4. $E(X+Y)=E(X)+E(Y)$

12-5. 確率変数の分散

確率変数の分散は、確率変数のとり得る値と期待値の差の2乗と確率との積を、全て足し合わせたもの

■離散型確率変数の場合
Xの期待値を$\mu$とすると、
$V(X) = \sum _{i=1}^n(x_i-\mu)^2p_i$

■連続型確率変数の場合
$V(X) = \int_{-\infty}^\infty(x-\mu)^2f(x)dx$

【分散を期待値から求める】
$V(x) = E(x^2) - {E(x)}^2$

12-6. 分散の性質

1. $V(C)=0$
2. $V(X+C)＝V(X)$
3. $V(kX)=k^2V(X)$
4. $V(X+Y)=V(X)+V(Y)$(XとYが独立である場合)

練習問題(12. 累積分布関数と確率変数の期待値・分散)

## 13. いろいろな確率分布

13-1. 二項分布

■ベルヌーイ試行
コインを投げたときに表が出るか裏がでるかのように、何かを行ったときに起こる結果が2つしかない試行のことを「ベルヌーイ試行」という
$P(X=1)=p$
$P(X=0)=1-p$

■二項分布
ベルヌーイ試行をn回行って成功する回数xが従う確率分布を「二項分布という」

■二項分布のグラフ

13-2. 二項分布の期待値と分散

確率変数xが二項分布Ｂ(n,p)に従うとき、Ｘの期待値Ｅ(X)と分散Ｖ(X)は以下のようになる
$E(X)=np$
$V(X)=np(1-p)$

13-3. ポアソン分布

■ポアソン分布の素となる二項分布

$P(X=k)= _nC_kp^k(1-p)^{n-k}$

■ポアソン分布
二項分布でn→∞、p→０に近づけるとポアソン分布に近似する
$P(X=k) = \frac{e^{-\lambda}\lambda^k}{k!}$

13-4. ポアソン分布の期待値と分散

確率変数がポアソン分布に従っているとき、ｘの期待値と分散は次のようになります
$E(X) = \lambda$
$V(X) = \lambda$

13-5. 幾何分布

成功確率がｐである独立なベルヌーイ試行を繰り返すとき、初めて成功するまでの試行回数ｘが従う確率分布を「幾何分布」という

$P(X=k)=(1-p)^{k-1}P$

13-6. 幾何分布の期待値と分散

確率変数xが成功確率ｐの幾何分布に従っているとき、その期待値と分散は以下のようになる
$E(X) = \frac{1}{p}$
$V(X) = \frac{1-p}{p^2}$

13-7. 超幾何分布

■超幾何分布
AとBで構成されるN個からなる集団があり、AがM個、BがN-M個であるとする
この集団から取り出されたn個の中に含まれるAの個数が従う確率分布を「超幾何分布」という

「捕獲再捕獲法」
ほとんど移動しない生物や個体数が変化する生物に対して個体数の推定を行う場合には適していない

■超幾何分布の期待値と分散
確率変数xが超幾何分布に従っているとき、その期待値と分散は以下のようになる
$E(X) = n･\frac{M}{N}$
$V(X) = n･\frac{M(N-M)}{N^2}･\frac{N-n}{N-1}$

超幾何分布は、2つの性質で構成される集団から非復元法抽出法でサンプルを採取した場合の確率分布
Nが無限に大きい場合は、二項分布に近似てくる

13-8. 負の二項分布

【定義1】
成功確率がｐである独立なベルヌーイ試行を繰り返すとき、ｋ回成功するまでの失敗回数ｘが従う確率分布を「負の二項分布」という
$P(X=x) = _{k+x-1}C_xp^k(1-p)^x$

【定義2】
成功確率がｐの試行において、ｋ回成功するまでにｘ回試行する確率は次の式で計算できる
$P(X=x) = _{x-1}C_{k-1}p^k(1-p)^{x-k}$

■負の二項分布の期待値と分散
<定義1>
$E(X) = k\frac{1-p}{p}$
$V(X) = k\frac{1-p}{p^2}$
<定義2>
$E(X) = \frac{k}{p}$
$V(X) = k\frac{1-p}{p^2}$

練習問題(13. いろいろな確率分布1)

## 14. いろいろな確率分布2

14-1. 正規分布

正規分布に伴う確率変数xの確率密度f(x)は次の式で表される
$f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$

確率変数xの期待値と分散は次のようになる
$E(X) = \mu$
$V(X) = \sigma^2$

■正規分布のグラフ
正規分布は平均を中心に左右対称で、教会にあるベルのような形をしていることから、「ベルカーブ」ともよばれる

14-2. 正規分布の再生性と標準正規分布

■正規分布の再生性

■標準正規分布
正規分布の中で、特に「平均$\mu=0$、分散$\sigma^2=1$」である正規分布を「標準正規分布」という

14-3. 標準化したデータの使い方

標準化した値は「$ｚ$値」または「標準化得点という」
$z = \frac{x-\mu}{\sigma}$

$偏差値 = 50 + 10\times z$

14-4. 標準正規分布表

標準正規分表は「あるz値以上(以下)が生じる確率」をまとめた表

14-5. 標準正規分布表の使い方1

14-6. 標準正規分布表の使い方2

$z$軸と標準正規分布で囲まれた部分の面積は「1」

練習問題(14. いろいろな確率分布2)

## 15. いろいろな確率分布3

15-1.指数分布

■指数分布

指数分布は、連続型確率分布の一つで、次に何かが起こるまでの期間が伴う分布
$f(x)=\lambda e^{-\lambda x}$

確率変数xが指数分布に従っているとき、xの期待値と分散は次のようになる
$E(X) = \frac{1}{\lambda}$
$V(X) = \frac{1}{\lambda^2}$

■指数分布の使い方
ある期間に平均して$\lambda$回起こる現象が次に起こるまでの期間を$x$としたとき、「期間$X$が$x$以下となる確率」すなわち「$x$までの累積分布関数$F(x)$」は次のようになる
$F(x) = P(X\leq x) = \int_{-\infty}^xf(t)dt = \int_0^x\lambda e^{-\lambda t}dt = 1-e^{-\lambda x}$

【指数分布とポアソン分布】
- 指数分布  次に起こるまでの「期間」に関する分布
- ポアソン分布  ある期間に起こる「回数」に関する分布

15-2. 離散一様分布

一様分布には、離散一様分布と連続一様分布がある
一様分布は、すべての事象の起こる確率が等しい分布のこと
$P(X=k) = \frac{1}{N}$
$x$の期待値と分散はつぎのようになる
$E(X)=\frac{N+1}{2}$
$V(X)=\frac{N^2-1}{12}$

15-3. 連続一様分布1

確率変数$x$が$a\leq x \leq b$における連続一様分布に従うとき、確率密度関数は次のようになる
$f(x) = \frac{1}{b-a}$

期待値と分散は次のようになる
$E(X) = \frac{a+b}{2}$
$V(X) = \frac{(b-a)^2}{12}$

15-4. 連続一様分布2

15-5. 2変数の確率分布

■離散型同時確率分布

■連続型同時確率分布

15-6. 2変数の期待値と分散

■2つの確率変数の期待値
$E(X+Y) = E(X) + E(Y)$
$E(XY) = E(X)E(Y)$

■2つの確率変数の分散
$V(X+Y) = V(X) + V(Y) + 2Cov(X, Y)$
$V(X-Y) = V(X) + V(Y) - 2Cov(X, Y)$

■２つの確率変数の共分散
$Cov(X, Y) = E[(X-\mu_x)(Y-\mu_y)] = E(XY)-\mu_x \mu_y$

■相関係数...共分散を標準偏差で割ったもの
$\rho = \frac{Cov(X, Y)}{\sqrt{V(X)V(Y)}}$

練習問題(15. いろいろな確率分布3)

## 16. 標本と抽出法

16-1. 母集団と標本

本来知りたいと思っている集団全体のことを「母集団」という
母集団の情報を推測するために選ばれた一部の集団のことを「標本」という

母集団から一部を選んで標本とすることを「抽出」という
母集団から抽出された標本を用いて、母集団の性質を推測することを「推測統計学」という
取得した手元のデータを用いて、データの特徴をグラフや表などを用いて分かりやすく表現することを「記述統計学」という

母集団には、有限母集団と無限母集団がある

【有限母集団修正】
有限母集団から標本を抽出する場合、標本を抽出するたびに母集団のデータが減ってしまうために推定値に偏りが出てしまう可能性がある
平均値の分散を求める場合、$\frac{N-n}{N-1}$をかけて「有限母集団修正」を行う

16-2.全数調査と標本調査

標本調査では「単純無作為抽出」が基本

標本の抽出法
- 復元抽出法
- 非復元抽出法

【標本の大きさと標本数】
100人を抽出してアンケートを行うという調査を5回繰り返す
- 標本の大きさは、100(サンプルサイズ)
- 標本数は、5(サンプル数)

16-3. 標本の抽出方法

単純無作為抽出法は、最も基本的な方法だが、手間と時間がかかる場合がある
手間を軽減させた様々な無作為抽出法

■層化抽出法(層別抽出法)
母集団をあらかじめいくつかの層(グループ)に分けておき、各層から必要な数の調査対象を無作為に抽出する方法

■クラスター抽出法(集落抽出法)
1. 母集団を、小集団である「クラスター(集落)」に分ける
2. 分けられたクラスターの中から、いくつかのクラスターを無作為抽出する
3. それぞれのクラスターにおいて全数調査を行う

■多段抽出法
母集団をいくつかのグループに分け、そこから無作為抽出でいくつかのグループを選び、さらにその中から無作為抽出でいくつかのグループを選び・・・という操作を繰り返して、最終的に選ばれたグループの中から調査対象を無作為抽出する方法

■系統抽出法
通し番号をつけた名簿を作成し、1番目の調査対象を無作為に選び、2番目以降の調査対象を一定の間隔で抽出する方法

■二相抽出法
層化抽出を行いたいが母集団の情報がない場合、まず母集団から標本を抽出して母集団の情報を取得し(第一相)、その情報をもとに層化抽出を行う(第二相)方法

16-4. 研究デザイン

■実験研究
研究対象に対してなんらかの介入を行い、その効果を検証するための研究デザイン

- ランダム化比較試験(RCT)
  実験群と対照群への割り付けをランダムに行い、介入の効果を調べる研究
- クロスオーバー試験(前向き研究)
  ランダム化比較試験の後、一定の期間をあけてから実験群と対照群を入れ替えて再度介入を行い、比較を行う

■観察研究
研究対象に対して介入を行わず、観察によってデータを集めて解析を行う研究デザイン

- 横断研究
  ある1時点において断面的調査を行い、要因と結果の関連を調べる研究
- ケースコントロール研究(症例対照研究)(後ろ向き研究)

練習問題(16. 標本と抽出法)

## 17. 大数(たいすう)の法則と中心極限定理

17-1. 大数の法則1

大数の法則：
確率$p$でおこる事象において、試行回数を増やすほど、その事象が実際に起こる確率は$p$に近づく
母平均が$\mu$である集団から標本を抽出する場合、サンプルサイズが大きくなるにつれて、標本平均は母平均$\mu$に近づく

17-2. 大数の法則2

17-3.中心極限定理1

中心極限定理：
標本を抽出する母集団が平均$\mu$、分散$\sigma^2$の正規分布に従う場合においても、従わない場合においても、抽出するサンプルサイズがおおきくなるにつれて標本の分布は、平均$\mu$、分散$\sigma^2$の正規分布に近づく

17-4. 中心極限定理2

練習問題(17. 大数の法則と中心極限定理)

## 18. 母平均の点推定

18-1. 点推定とは

推測統計学の中には「推定」と「検定」が含まれる

■推定
母集団を特徴づける母数(パラメータ(平均など))を統計学的に推測すること

■検定
母集団から抽出された標本の統計量に関する仮説が正しいかを統計学的に判定すること

推定には「点推定」と「区間推定」という2つの方法がある
- 点推定
  平均値などを1つの値で推定すること
- 区間推定
  平均値などをある区間でもって推定すること

【母数】
母数は、母集団を特徴づける値のこと
たとえば、母平均や母分散など

18-2. 母平均の点推定と推定量・推定値

推定された値は一般的に^(ハット)を頭につけて表す
例)母平均$\mu$の推定値は$\hat{\mu}$

■推定量
パラメータを推定するために利用する数値の計算方法や計算式を「推定量」という

■推定値
実際に試行を行った結果から計算した値を「推定値」と呼ぶ

18-3. 推定量の性質

■一致性について
推定量を元に母平均や母分散のような分布のパラメータを推測するとき、その推測が正確である必要がある
大数の法則は、サンプルサイズが大きくなると、標本平均が母平均に近づくという法則
このようにサンプルサイズが大きくなれば、推定量がだんだんと真のパラメータに近づく性質を「一致性」という

■不偏性について
推定量を元に母平均や母分散のような分布のパラメータを推測するとき、その推測が真のパラメータから大きく外れてしまっては意味がない
推定量の期待値がパラメータに一致する必要がある
この性質を「不偏性」という

■標本平均の性質
標本平均は、一致推定量であり不偏推定量である
そのため、標本平均の値を母平均の推定量として使うことができる

18-4. 標本分散と不偏分散

母平均の点推定を行うと不偏分散が出力される
母分散を$\sigma^2$、標本分散を$S^2$、不偏分散を$s^2$で表す

■標本分散
$S^2 = \frac{1}{n}\sum_{i=1}^n(x_i-\overline{x})^2$

■不偏分散
$s^2 = \frac{n}{n-1}\times \frac{1}{n}\sum_{i=1}^n(x_i-\overline{x})^2 = \frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2$

18-5. 標準偏差と標準誤差

母平均の点推定を行うと、不偏分散のほかに「標準偏差」と「標準誤差」が出力される

■標準偏差
$s = \sqrt{s^2}$

■標準誤差
標準誤差(SE: standard error)は推定量の標準偏差
推定量そのもののばらつき(=精度)を表す
標準誤差は一般的に標本平均の標準偏差を意味する
$SE = \sqrt \frac{s^2}{n} = \frac{s}{\sqrt{n}}$

練習問題(18. 母平均の点推定)

不偏分散の平方根をとったものは、標準偏差の不偏推定量とはならない

## 19. 母平均の区間推定(母分散既知)

19-1. 区間推定とは

区間推定は、母集団の従う分布が正規分布であると仮定できるときに、標本から得られた値を使ってある区間でもって母平均などの母数を推定する方法
このときの区間のことを信頼区間（CI）という

母平均の区間推定では、母分散が分かっている場合と分からない場合とでその算出方法が異なる

- 母分散が分かっている場合(母分散既知)
  母分散の値を使い、標準正規分布を用いて信頼区間を算出する
- 母分散が分からない場合(母分散未知)
  不偏分散の値を使い、t分布を用いて信頼区間を算出する

母平均が分からないのに母分散が分かっているという状況は現実的に稀
よって、通常母平均の区間推定を行う場合にはt分布を用いた方法が使われる

■95％信頼区間(95%CI)
母集団から標本をとってきて、その標本平均から母平均の95％信頼区間を求めるという作業を100回やったときに、95回はその区間の中に母平均が含まれることを意味する

95％のようにある区間に母数が含まれる確率のことを「信頼係数」あるいは「信頼度」という

19-2. 母平均の信頼区間の求め方(母分散既知)

標本平均$\overline{x}$の標準化
$\frac{\overline x - \mu}{\sqrt{\frac{\sigma^2}{n}}}$

標準正規分布における95％のz値は1.96

$-1.96\leq \frac{\overline x - \mu}{\sqrt{\frac{\sigma^2}{n}}} \leq 1.96$

【パーセント点】
ある値▲より大きくなる確率が☆％であるとき、この▲のことを「上側☆％点」という
ある値▲より大きくなる確率のことを「上側確率」という

19-3. 95％信頼区間のもつ意味

母集団から標本をとってきて、その平均から95％信頼区間を求めるという作業を100回やったときに、95回はその区間の中に母平均が含まれるという頻度もしくは割合を意味する

【信用区間】
信用区間はベイズ統計学における区間推定で使われる
母平均の区間推定を行ったときの95％信用区間とは「母平均が95％の確率で推定された信用区間に含まれる」という意味

19-4. さまざまな信頼区間(母分散既知)

- 信頼係数90％
  上側5％点は、1.64
- 信頼係数95％
  上側2.5％点は、1.96
- 信頼係数99％
  上側0.5％点は、2.58

信頼係数が大きいほど、信頼区間の幅は広くなる

サンプルサイズnが大きいほど、信頼区間の幅は狭くなる

練習問題(19. 母平均の区間推定(母分散既知))

## 母平均の区間推定(母分散未知)

20-1. 標本とt分布

- 母平均$\mu$、標本平均$\overline{x}$
- 母分散$\sigma^2$、標本分散$s^2$

母分散が分からない場合、不偏分散$s^2$とt分布を使って母平均の区間推定を行う

t分布は、標準正規分布とよく似た形の分布で、パラメータである「自由度(df)」によって分布の形が変わるという特徴を持っている
自由度が大きくなるにつれて標準正規分布に近づく
$t = \frac{\overline{x}-\mu}{\sqrt{\frac{s^2}{n}}}$

■t分布の性質
1. t分布の成り立ち
   標準正規分布に従うZと自由度nのカイ二乗分布Wがあり、これらが互いに独立であるとき、次の式から算出されるtは自由度ｎのt分布に従う
   $t = \frac{Z}{\sqrt{\frac{W}{n}}}$

2. 期待値と分散
   確率変数$x$が自由度$m$のt分布に従っているとき、$x$の期待値と分散は次のようになる
   $E(X) = 0 (m>1)$
   $V(X) = \frac{m}{m-2} (m>2)$

20-2. t分布表

$t_\alpha(v)$
$v=n-1$

【サンプルサイズが大きい時】
サンプルサイズが30以上であれば、ほぼ正規分布になる

20-3. 母平均の信頼区間の求め方(母分散未知)

20-4. 母平均の信頼区間の求め方(母分散未知) -Excel統計

1. 標本の推定と検定
2. 母平均の推定
3. オプションの設定
   - データ内容: 実データ
   - 確率分布: t分布
   - 母集団: 無限母集団
   - 信頼度: 95%

20-5. さまざまな信頼区間(母分散未知)

- 信頼係数が大きいほど、信頼区間の幅は広くなる
- サンプルサイズが大きいほど、信頼区間の幅は狭くなる

20-6. 母平均の差の信頼区間

■対応があるデータの場合

■対応がないデータの場合

【母平均の差の検定と正規分布の再生性】

練習問題(20. 母平均の区間推定(母分散未知))

## 21. 母比率の区間推定

21-1. 母比率の信頼区間の求め方1

二項分布に従う確率変数$x$の期待値と分散は次のとおり
$E(X) = np$
$V(X) =np(1-p)$

$Z = \frac{\hat{p}-p}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}$

21-2. 母比率の信頼区間の求め方2

21-3. 母比率の信頼区間の求め方 -Excel統計

21-4. 必要なサンプルサイズ1

21-5. 必要なサンプルサイズ２

$\hat{p}=0.5$のとき信頼区間の幅が最も大きくなる

21-6. 母比率の差の信頼区間

練習問題(21. 母比率の区間推定)

## 22. 母分散の区間推定

22-1. カイ二乗分布

カイ二乗分布は、$z_1, z_2, ･･･, z_k$が互いに独立で標準正規分布に従う確立変数であるときに、次の式から算出される自由度$k$の$x^2$が従う確率分布のこと
$x^2 = Z_1^2+Z_2^2+･･･＋Z_k^2$

自由度が1のとき、カイ二乗分布は標準正規分布に従う確率変数を2乗したものに等しくなる
$x^2(1) = Z_1^2$

■カイ二乗分布の性質

1. 期待値と分散
   $E(X) = k$
   $V(X) = 2k$

2. 再生性
   $x_1,x_2$がそれぞれ独立に自由度$k_1,k_2$のカイ二乗分布に従うとき、$x_1+x_2$は自由度$k_1+k_2$のカイ二乗分布に従う

3. 正規分布に従う母集団からの無作為標本
   確率変数$x_1, x_2, ･･･, x_k$がそれぞれ独立に正規分布に従うとき、次の式から算出される値は自由度$k$のカイ二乗分布に従う
   $\sum_{i=1}^k(\frac{X_i-\mu}{\sigma})^2$ ~ $x^2(k)$

4. カイ二乗分布と指数分の関係
   自由度2のカイ二乗分布は$\lambda=\frac{1}{2}$の指数分布と一致する

22-2. カイ二乗分布表

22-3. 母分散の信頼区間の求め方1

母分散の区間推定では、カイ二乗分布を使う
$x^2 = \frac{(n-1)s^2}{\sigma^2}$

22-4. 母分散の信頼区間の求め方2

練習問題(22. 母分散の区間推定)

## 23. 検定の前に

23-1. 検定とは

検定は、確率をもとに結論を導く方法

検定は、最初に仮説を立て、実際に起こった結果を確率的に検証し、結論を導く
結論を導くには「背理法」を用いる
背理法とは、最初に仮説を設定し、仮説が正しいとした条件で考えて矛盾が起こった場合に仮説が間違っていると判断する方法

【検定を行う上での注意点】
■導かれた結論は「絶対に正しい」と考えることはできない
■「滅多にない」とする基準は先に決めておかなくてはならない

23-2. 検定で使う用語

■帰無仮説と対立仮説
- 帰無仮説
  検定の最初に立てる仮説($H_0$)
- 対立仮説
  帰無仮説に対する仮説($H_1$)

■検定統計量とP値
- 統計検定量
  帰無仮説が正しいと仮定したときに、観測した事象よりも稀なことが起こる確率を計算するための値
- P値
  帰無仮説が正しいと仮定したとき、観測した事象よりも稀なことが起こる確率のこと

■有意水準と棄却
帰無仮説を棄却する基準を有意水準という
有意水準は危険率と呼ばれることもある
P値が有意水準よりも小さい時は、帰無仮説は棄却される
P値が有意水準よりも大きい時は、帰無仮説は棄却されない
しかし、帰無仮説が正しいと結論づけるものではない（背理法なので）

23-3. 有意水準と検出力

■有意水準
有意水準は、検定において帰無仮説を設定したときにその帰無仮説を棄却する基準となる確率のこと
第1種の過誤(帰無仮説が正しいのに棄却する)を犯す確率（$\alpha$で表される）

■検出力
$1-\beta$で表される
帰無仮説が正しくないときに、正しく帰無仮説を棄却する確率
$\beta$は第2種の過誤(対立仮説が正しいのに採択されない)

23-4. 第1種の過誤と第2種の過誤

第1種の過誤$\alpha$も第2種の過誤$\beta$も低い方がよいが、両方はトレード・オフの関係になっているので、同時に低くすることはできない。
バランスをとることが重要。

23-5. 検定統計量と棄却域・採択域

■統計検定量
1. 統計量z (=z値)
   平均が0、分散が1となるようにデータを標準化した値
   $z = \frac{\overline{x}-\mu}{\sqrt{\frac{\sigma^2}{n}}}$
2. 統計量t (=t値)
      $t = \frac{\overline{x}-\mu}{\sqrt{\frac{s^2}{n}}}$

23-6. 両側検定と片側検定

練習問題(23. 検定の前に)

## 24. 平均値の検定

24-1. 母平均の検定(両側t検定)

検定は次の流れに従って行う
1. 仮説を立てる
2. 有意水準を設定する
3. 適切な検定統計量を決める
4. 棄却ルールを決める
5. 検定統計量を元に結論を出す

24-2. 母平均の検定(片側t検定)

24-3. 2標本t検定とは

2つの独立した母集団があり、それぞれの母集団から抽出した標本の平均に差があるかどうかを検定することを「2標本t検定」という
2つのデータが「対応のあるデータ」か「対応のないデータ」かによって検定統計量の算出方法が異なる

■対応がない場合の2標本t検定の方法

- プールした分散
  プールした分散とは、2つの標本の不偏分散を1つにまとめたもの
  $s^2 = \frac{(n_1-1)\times s_1^2 + (n_2-1)\times s_2^2}{n_1 + n_2 - 2}$

■対応がある場合の2標本t検定の方法

24-4. 対応のない2標本t検定

【ウェルチのt検定】
2つの標本の母分散が等しいと仮定できない場合、「ウェルチのt検定」を使う

24-5. 対応のある2標本t検定

練習問題(24. 平均値の検定)

## 25. さまざまな検定

25-1. 母比率の検定

$z = \frac{\hat{p}-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$

25-2. 二項分布を用いた検定

$z = \frac{X-np}{\sqrt{np(1-np)}}$

■連続修正

25-3. ポアソン分布を用いた検定

$z= \frac{X-n\lambda}{\sqrt{n\lambda}}$

25-4. 適合度の検定

調査によってい得られたクロス集計表がある場合、実測度数がある特定の分布に適合(一致)するかどうかを検定することを適合度の検定という
適合度の検定では、カイ二乗分布を用いて検定を行う

カイ二乗値$x^2$は、「理論値」と「実測値」の差を2乗したものを「理論値」で割り、和をとる

25-5. 独立性の検定

2つ以上の分類基準を持つクロス集計表において、分類基準間に関連があるかどうかを検定することを独立性の検定という
この場合にもカイ二乗分布による検定を行う

■イェーツの補正
イェーツの補正は、2行✕2列のクロス集計表のデータに対して行われる補正

25-6. 独立性の検定 -Excel統計

25-7. 母比率の差の検定

$z = \frac{\hat{p_1}-\hat{p_2}}{\sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1}+\frac{1}{n_2})}}$

練習問題(25. さまざまな検定)

## 26. 相関分析

26-1. 散布図

2つの要素からなる1組のデータが得られたときに、2つの要素の関係を見るためにプロットしたグラフを散布図という
1つ目の要素を横軸に、2つ目の要素を縦軸にとり、各データを該当する位置にプロットする
2つの要素の間に何らかの関係がある場合、これらのデータ間には「相関関係」があるという

26-2. 正の相関と負の相関

正の相関 ...右上がりのグラフ
負の相関 ...右下がりのグラフ

■相関関係と因果関係

26-3. 相関係数

直線的な相関関係の強さを表す指標のひとつに「相関係数(ピアソンの積率相関係数)」がある

$r_{xy}=\frac{共分散_{xy}}{標準偏差_x \times 標準偏差_y}
= \frac{\frac{1}{n}\sum_{i=1}^n(x_1-\overline{x})(y_i-\overline{y})}{\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\overline{x})^2}\times \sqrt{\frac{1}{n}\sum_{i=1}^n(yi-\overline{y})^2}}$

相関係数の特徴
- rは-1から1までのいずれかの値をとる
- |r|が1に近いほど相関が強く、0に近いほど相関が弱い
- |r|が0に近くても、何らかの関係がある場合がある
- rは単位をもたない値であり、データの単位がどのようなものであっても計算できる
- 相関係数は直線的な相関関係の強弱を表すものであり、二次関数のような線形ではない相関関係の強弱は正しくあらわすことができない

■無相関の検定
標本から算出した相関係数を使って、母集団の相関係数が0かどうかを検定することを無相関の検定という
帰無仮説は「母相関係数は0である」
t分布を用いて行う
$t = \frac{|r|\sqrt{n-2}}{\sqrt{1-r^2}}$

■母相関係数の信頼区間
母相関係数の信頼区間を求めるためには、まず標本から算出した相関係数rを変換する(フィッシャーのz変換)
$z = \frac{1}{2}\log\frac{1+r}{1-r}$
同様に、母相関係数$\rho$をz変換したものを$\zeta$とする
$\zeta = \frac{1}{2}\log \frac{1+\rho}{1-\rho}$
$z値 = \sqrt{n-3}(z-\zeta)$

26-4. 偏相関係数

見かけ上の相関がある場合は、相関係数ではなく第3の因子の影響を除いた「偏相関係数」を用いて相関関係を評価する
$r_{xy･z} = \frac{r_{xy}-r_{xz}r_{yz}}{\sqrt{1-r_{xz}^2}\sqrt{1-r_{yz}^2}}$

26-5. 層別解析

データの中にいくつかの異なる性質の集団が含まれている場合、データを分割して解析することができる
この方法を「層別解析」という

練習問題(26. 相関分析)

## 27. 回帰分析

27-1. 単回帰分析

回帰とは、目的変数$y$について説明変数$x$を使った式で表すことをいう
この式のことを「回帰方程式」あるいは「回帰式」という
また、回帰式を求めることを「回帰分析」という

説明変数$x$が1つだけ用いられている回帰式を「単回帰式」という
単回帰式を求めることを「単回帰分析」という

一方、説明変数を複数使った回帰式を求めることもできる
このような式を「重回帰式」といい、重回帰式を求めることを「重回帰分析」という

■単回帰式$y = \beta_0 + \beta_1x$における$\beta_0$と$\beta_1$の求め方
実際のデータには誤差($u$)が含まれているので、次のような回帰式を考える
$y = \beta_0 + \beta_1x + u$

すべてのデータの誤差$u$が最小になる$\beta_0$と$\beta_1$を求める

$u_i = y_i - (\beta_0 + \beta_1x_i)$
■最小二乗法
$\sum_{i=1}^ne_i^2 = \sum_{i=1}^n(y_i-(\hat{\beta_0}+\hat{\beta_1x_i}))^2$
$e_i$は「残差」とよばれるもので、誤差$u_i$とは異なる

最小二乗法により推定された$\hat{\beta_0}$と$\hat{\beta_1}$は「偏回帰係数」と呼ばれる

【$\beta_0$と$\beta_1$の求め方】
$\hat{\beta_1} = \frac{\sum_{i=1}^n(y_i-\overline{y})(x_i-\overline{x})}{\sum_{i=1}^n(x_i-\overline{x})^2}$
$\hat{\beta_0} = \overline{y} - \hat{\beta_1}\overline{x}$

【誤差$u_i$の仮定】
回帰モデルを考えるにあたって、誤差$u_i$にはいくつかの仮定している条件がある
1. $u_i$の期待値は0: $E(u_i) = 0 $
2. $u_i$の分散は常に$\sigma^2$である: $V(u_i) = \sigma^2$
3. 異なる誤差$u_i$、$u_j$は互いに独立である: $Cov(u_i, u_j) = 0$
4. 誤差$u_i$は正規分布に従う

27-2. 最小二乗法

■回帰式の特徴
1. 推定値$\hat{y}$の平均値は、実際の観測値$y_i$の平均と等しい
2. 回帰直線は$(\overline{x}, \overline{y})$を通る

27-3. 重回帰分析

重回帰分析は、複数の説明変数を用いて目的変数を表す回帰式を算出すること
$y = \beta_0 + \beta_1x_1 + \beta_2x_2 + ･･･ + \beta_ix_i$

重回帰分析の偏回帰係数も、単回帰分析と同様に最小二乗法で求める

■偏回帰係数
ある偏回帰係数は、それ以外の説明変数の値を固定した場合に、その説明変数が1増加すると目的変数がどれだけ増加/減少するかを示している


■標準偏回帰係数
標準偏回帰係数は、説明変数および目的変数をそれぞれ標準化した値から算出される偏回帰係数のこと
標準偏回帰係数は、重回帰式における各変数の重要性を表す指標であり、標準偏回帰係数どうしの大小を比較できる

■偏回帰係数の有意性の検定
偏回帰係数の有意性の検定とは、定数項も含めた各偏回帰係数が0であるかについての検定
帰無仮説は「偏回帰係数=0」
偏回帰係数を標準誤差で割った値について、自由度(n-k-1)のt分布を用いて検定を行う
$t_i = \frac{\hat{\beta_i}-0}{se(\hat{\beta_i})}$

■偏回帰係数の信頼区間
$\hat{\beta_i}-t_{\frac{\alpha}{2}}(n-k-1)\times se(\hat{\beta_i})\leq \beta_i \leq \hat{\beta_i} + t\frac{\alpha}{2}(n-k-1) \times se(\hat{\beta_i})$

■ダミー変数
ダミー変数とは、カテゴリカルデータや2値型データのようなもともと数値でないデータに対して、0と1を用いて数量化した変数のこと

27-4. 予測値と残差
予測値と実際のデータとの差を「回帰残差」あるいは「残差」という
$e_i = y_i - (\hat{\beta_0}+ \hat{\beta_1}x_i)$

■残差と誤差
残差は「推定」された回帰式から算出される値と実際のデータとの差
誤差は「真の」回帰式から算出される値と実際のデータとの差(計算で求められない)

■残差の性質
- 残差の総和は0である
- 説明変数と残差の積和は0である
  このことは説明変数と残差が無相関ということを示している

■残差の評価
回帰式を評価する方法は、決定係数を算出する方法のほかに、残差のばらつきを見る「残差分析」という方法がある
回帰式が妥当であれば、残差は適当にばらつく(分散均一性)
残差プロット

27-5. 決定係数と重相関係数

■決定係数
決定係数は、データに対する推定された回帰式の当てはまりの良さ(度合い)を表す
決定係数は一般に$R^2$で示され、0から1までの値をとる
1に近いほど回帰式が実際のデータに当てはまっていることを表している

■決定係数の求め方
決定係数を求めるためには、実際のデータと推定された回帰式から「全変動」「回帰変動」「残差変動」の3つを求める必要がある
- 全変動
  実際のデータとデータ全体の平均値との差の平方和
- 回帰変動
  予測値とデータ全体の平均値との差との平方和
- 残差変動
  実際のデータと予測値との差との平方和

全変動 = 回帰変動 + 残差変動

決定係数 = 回帰変動 / 全変動

■自由度調整済み決定係数
決定係数は説明変数の数が増えるほど1に近づく
そのため、説明変数が多い場合には、これを補正した「自由度調整済み決定係数」を使う
自由度調整済み決定係数 = 1 - ((残差変動/(n-k-1)) / (全変動/(n-1)))

■重相関係数
重相関係数は、実際に観測された目的変数の値と、重回帰式をあてはめて計算した推定値との相関係数
重相関係数は一般に$R$で示され、0から1の間の値をとる
1に近いほど分析の精度は高い

27-6. 回帰の有意性の検定

複数の説明変数における回帰係数の効果を同時に検定する場合にはF分布を用いて回帰の有意性の検定を行う
$F = \frac{MSR}{MSE}$
この検定では片側検定を行う

■分散分析表

27-7. 重回帰分析の実行 -Excel統計

27-8. 重回帰分析の出力 -Excel統計

練習問題(27. 回帰分析)

## 等分散性の検定とWelchのt検定

28-1. F分布

F分布はt分布やカイ二乗分布と同様、自由度により形が異なる分布
2つの自由度から分布の形が決まる
$F = \frac{x_1^2/k_1}{x_2^2/k_2}$

■F分布の使い方
2標本の不偏分散を用いて母分散が等しいかどうかを検定する「等分散性の検定」に使われる

■F分布の形

■F分布の性質
1. 期待値と分散
$E(X) = \frac{n}{n-2}$
$V(X) = \frac{2n^2(m+n-2)}{m(n-2)^2(n-4)}$

2. t分布とF分布の関係
   tが自由度nのt分布に従うとき、$t^2$は自由度(1,n)のＦ分布に従う

28-2. F分布表

■t検定を行うための前提条件
- 標本は母集団からランダムに選ばれている
- 母集団の分布は正規分布に従う
- 2標本t検定を行う場合には、2つの母集団の母分散が等しい ...F分布表で検定

28-3. 母分散の比の信頼区間の求め方

$F = \frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2}$
上側信頼区間がF(n,m)の場合、下側信頼区間は$\frac{1}{F(m,n)}$

28-4. 等分散の検定

$F = \frac{s_1^2}{s_2^2}$
等分散性の検定においてF統計量を算出するときには大きな値を分子にする

28-5. Welchのt検定

2標本のt検定を行う場合、2つの母集団の分散が等しいことが必要
等しくないとは言えない場合: t検定を実施
等しくない場合: Welchのt検定
※等分散の検定を行わず、Welchのt検定を行ったほうが良いという考え方も一般的になりつつある

■Welchのt検定
Welchのt検定は、2標本t検定と同様に「平均値の差」の検定方法
$t = \frac{\overline{x_1}-\overline{x_2}}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$

【多重性の問題】
多重性の問題とは、検定を複数回行うと第1種の過誤の確率が大きくなるという問題

【ボンフェローニ法】
有意水準$\alpha$を$\frac{\alpha}{k}$とする
事象$k$の数が大きくなると有意水準が非常に小さくなるため検出力が低下する
有意になりにくい保守的な検定方法

練習問題(28. 等分散性の検定とWelchのt検定)

## 29. 一元配置分散分析

29-1. 分散分析とは

3群以上からなるデータの母平均の差を検定する分散分析

分散分析は、群ごとのデータのばらつきを元に「F分布」を用いて検定を行う
分散分析を行うにあたっては、「分散分析表」を作成する
帰無仮説は「各群の母平均は等しい」となる

■分散分析で使う用語
- 要因： データの値に変化を与える要素のこと
- 因子： 要因の中でも特に母平均に差をもたらすと考えられることから研究対象となる(あるいは注目する)要因を指す
- 水準： 1つの要因に含まれる項目(グループ)のこと
- 〇元配置： データに含まれる因子の数

■分散分析の種類
- 一元配置分散分析
- 二元配置分散分析
- 多元配置分散分析

29-2. 一元分散分析の流れ1

分散分析のポイントは、「データ全体の平均値から因子の各水準の平均値がどのくらいずれているのか」を見ること

■分散分析のイメージ
a: 全体の平均値からの各データのズレ
b: 全体の平均値からの因子の各水準の平均値のズレ
c: それ以外のズレ(因子の各水準の平均値から各データのズレ)
$\sum a^2 = \sum b^2 + \sum c^2$

29-3. 一元配置分散分析の流れ2

■分散分析表
因子  | 平方和  | 自由度  | 平均平方  | F値
要因  | $\sum b^2$ | 水準の個数-1 | 平方和/自由度  |要因の平均平方/残差の平均平方
残差  | $\sum c^2$ | 全体の自由度-要因の自由度  | 平方和/自由度 |
全体  | $\sum a^2$ | n-1  | - |

29-4. 一元配置分散分析の流れ3

分散分析は、「要因の平均平方」と「残差の平均平方」の比を用いて検定を行う
平均平方の比は「F分布」を用いて検定できる

要因のばらつきが相対的に大きいかどうかだけを見ればよいので、「片側検定」を行う

■各水準の母平均の信頼区間

29-5. 一元配置分散分析 -Excel統計

練習問題(29. 一元配置分散分析)

## 30. 二元配置分散分析

30-1. 二元配置分散分析の分散分析表1

二元配置分散分析は、因子を2つ含むデータから、各因子における水準間の平均値の差を検定するための分析方法

二元配置分散分析のポイントも「データ全体の平均値から因子の各水準の平均値がどのくらいずれているか」を見ること

一元配置分散分析とはことなり「相互作用」の有無についても解析可能

【二元配置分散分析の分散分析表】
因子  平方和  自由度  平均平方  Ｆ値
因子Ａ
因子Ｂ
因子Ａかつ因子Ｂ
残差
全体

30-2. 二元配置分散分析の分散分析表2

30-3. 二元配置分散分析の分散分析表3

■F値について
統計量Fは「各因子の平均平方」を「残差の平均平方」で割って算出

30-4. 二元配置分散分析の分散分析表4

繰り返しのある二元配置分散分析では交互作用を算出できる
繰り返しのない二元配置分散分析では交互作用を算出できない

30-5. 交互作用とは

■交互作用図

練習問題(30. 二元配置分散分析)

## 31. 実験計画

31-1. フィッシャーの3原則

【フィッシャーの実験計画法に関する3つの原則】
1. 反復
2. 無作為化
3. 局所管理

■反復
複数の処理を比較する際に、それぞれの処理に対して同じ条件で2回以上の繰り返し実験(評価)を行う

■無作為化
実験の順序や場所などが複数ある場合に、比較したい処理群を無作為に割り付けること

■局所管理
反復と無作為化に加え、局所管理も盛り込んだ実験デザインを「乱塊法」という
乱塊法とは、実験計画において実験全体を無作為化するのではなく、局所管理の考えに基づくブロック内に1セットの実験を集めて無作為化を行う方法のこと

31-2. 効果量1

サンプルサイズが大きい方が母平均をより正確に推測できる
しかし、安全性に関する実験やコストの高い実験では、むやみやたらとサンプルサイズを大きくすることはできない
「有意水準」「効果量」「検出力」を考えた上でサンプルサイズを考える

■効果量
効果量は「検出したい差の程度」や「変数間の関係の強さ」のことで、その実験の効果を見るための指標
P値は、その値より極端な値をとる確率を示したものに過ぎないため、その実験において実際にどの程度の効果があったかを知ることはできない
例えば同じ平均値の2群を比較した場合、サンプルサイズが大きい方がP値は小さくなる

31-3. 効果量2

効果量を表す指標にはさまざまなものがあるが、大きく分けると「d族」と「r族」がある

- d族： 差の大きさを表す
- r族： 相関の強さを表す

■Cohenのd
$d = \frac{|\overline{x_1} - \overline{x_2}|}{s_c}$
$s_c = \sqrt{\frac{n_1 s_1^2 + n_2 s_2^2}{n_1 +n_2}}$

■Hedgesのg
$g = \frac{|\overline{x_1} - \overline{x_2}|}{s_d}$
$s_d = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 +n_2 -2}}$

近年、P値を算出したときに、その実験にどのくらいの効果があったのかを示す上で、P値とともに効果量を報告することが推奨されている

31-4. 検出力

検出力が小さい場合、第2種の誤りを犯す可能性が高くなる

検出力は効果量が大きいほど大きくなる

多くの場合、検出力を0.8に設定する

サンプルサイズが大きいほど分布のばらつきは小さくなるため、検出力は大きくなる

31-5. 検出力の計算

サンプルサイズが大きくなるほど検出力は向上する
したがって、実験計画においてはじめに検出力を設定することで、必要なサンプルサイズを計算することができる

31-6. サンプルサイズの設計と検出力分析

サンプルサイズの設計や検出力分析を行うための4大因子
1. 有意水準
2. 検出力
3. サンプルサイズ
4. 効果量

■事前分析 -サンプルサイズの設計

■事後分析 -検出力分析
検出力分析には、有意水準、効果量、サンプルサイズの値が必要

## 32. その他

32-1. 外れ値

外れ値のうち、測定ミス・記入ミス等原因が分かっているものを「異常値」とよぶ場合がある

外れ値が見つかった場合、目的に応じて除外したり、データを変換したりすることがある

外れ値の探索の方法
- 箱ひげ図を描く
- 外れ値検定を行う
- クラスター分析を行う

■箱ひげ図を描く
ひげの範囲から外れた値は外れ値とみなされる

■外れ値検定を行う
「スミルノフ=グラブス検定」は、外れ値を検出するための検定

■クラスター分析を行う
クラスター分析を行った結果、データを1つしか含まないクラスターは外れ値の可能性が高いと考えられる

外れ値が疑われるデータが見つかった場合、本当に外れ値かどうかを吟味することが重要

32-2. 正規性の確認

データの正規性を確認する方法
- ヒストグラムを描く
- Q-Qプロットを描く
- 正規性の検定を行う

■Q-Qプロットを描く
縦軸： データの値
横軸： データの期待値を標準化した値

正規分布していると考えることができる場合、プロットが一直線に並ぶ

正規Q-Qプロットの作成手順
1. データを小さい順に並べたものを準備
2. 正規分布の累積分布関数を準備
3. 1.と2.のデータからそれぞれ分位数を取得
4. 1.のデータから取得した分位数を縦軸に2.のデータから取得した分位数を横軸にとりプロット

■正規性の検定を行う
正規性の検定方法
- 歪度によるダゴスティーノ検定
- 尖度によるダゴスティーノ検定
- 歪度と尖度によるオムニバス検定
- コルモゴロフ=スミルノフ検定
- シャピロ=ウィルク検定

32-3. 時系列データと移動平均

株価や気温など時間で細かく変化するデータを眺めると、変動が細かすぎて全体の傾向をつかみにくい場合がある
そのようなとき「移動平均」を用いることで、変化をより滑らかにしてデータを俯瞰できる

■移動平均の求め方
最も簡単な移動平均は、直近データの単純相加平均
項数が偶数のときは、一番離れている項については0.5倍して計算する

32-4. 時系列データにおける周期変動

時系列データの4つの変動
- 傾向変動(Trend)： 長期にわたる持続的な変化
- 循環変動(Cyclical)： 周期はいっていではないが3～15年ぐらいで周期的に繰り返される変化
- 季節変動(Seasonal)： 1年で繰り返される変化
- 不規則変動(Irregular)： 観測誤差など諸要因による変化

時系列モデル
- 乗法モデル： T ✕ C ✕ S ✕ I
- 加法モデル： T ＋ C ＋ S ＋ I

■各変動の抽出の流れ(乗法モデルの場合)
1. 期別平均法を用いて、季節変動(S)を算出
2. 季節変動(S)を用いて、観測値/S = TCSI/S = TCI を抽出
3. TCIに対して移動平均法または指数平滑法を用いて、トレンド(TC)を抽出
4. TCを用いて、TCI/TC = I を抽出

32-5. 自己相関

元データと時間をずらしたデータとの相関のことを「自己相関」という
元データからずらした量のことを「ラグ」という
ラグと自己相関を表したグラフを「コレログラム」という

32-6. さまざまな指数

指数とは、数値の変化や大小を比率として表したもの

3つの価格指数
■ラスパイレス指数
基準年の数量を重みとして算出した価格指数

■パーシェ指数
比較年の数量を重みとして算出した価格指数

■フィッシャー指数
ラスパイレス指数とパーシェ指数の幾何平均により算出